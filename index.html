<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Sparse view reconstruction via diffusion distillation.">
  <meta name="keywords" content="Sparse view, reconstruction, diffusion, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SparseFusion: Distilling View-conditioned Diffusion for 3D Reconstruction</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-YXDZHQRVSJ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-YXDZHQRVSJ');
</script>

<body>
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="index.html">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <!-- <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="#">
            #
          </a>
          <a class="navbar-item" href="#">
            #
          </a>
          <a class="navbar-item" href="#">
            #
          </a>
          <a class="navbar-item" href="#">
            #
          </a>
        </div>
      </div> -->
    </div>

  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SparseFusion: Distilling View-conditioned Diffusion for 3D Reconstruction</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.zhiz.dev/" target="_blank">Zhizhuo Zhou</a>,</span>
            <span class="author-block">
              <a href="https://shubhtuls.github.io/" target="_blank">Shubham Tulsiani</a></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Carnegie Mellon University</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">CVPR 2023</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2212.00792"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv (coming soon)</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/zhizdev/sparsefusion"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
              <!-- <span class="link-block">
                <a href="diverse.html"
                   class="external-link button is-normal is-rounded is-dark">
                  <span>Random Results</span>
                  </a>
              </span> -->

              <!-- <span class="link-block">
                <a href="comparison.html"
                   class="external-link button is-normal is-rounded is-dark">
                  <span>Random Comparisons</span>
                  </a>
              </span> -->

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <!-- <source src="https://i.imgur.com/DoEidnk.mp4"
                type="video/mp4"> -->
        <source src="static/images/teaser.mp4"
        type="video/mp4">
      </video>
      <h5 class="">
        <strong>SparseFusion</strong> reconstructs a consistent and realistic 3D neural scene representation from as few as 2 input images with known relative pose, while being able to generate detailed and plausible structures in uncertain or unobserved regions (such as front of the hydrant, teddybear's face, back of the laptop, or left side of the toybus).
        We show selected results below and random results <a href="diverse.html">here</a>.
      </h5>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-one">
          <video poster="" id="one" autoplay muted loop playsinline height="100%">
            <source src="static/images/focus-one.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-two">
          <video poster="" id="two" autoplay muted loop playsinline height="100%">
            <source src="static/images/focus-two.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-three">
          <video poster="" id="three" autoplay muted loop playsinline height="100%">
            <source src="static/images/focus-three.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-four">
          <video poster="" id="four" autoplay muted loop playsinline height="100%">
            <source src="static/images/focus-four.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-five">
          <video poster="" id="five" autoplay muted loop playsinline height="100%">
            <source src="static/images/focus-five.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-six">
          <video poster="" id="six" autoplay muted loop playsinline height="100%">
            <source src="static/images/focus-six.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-seven">
          <video poster="" id="seven" autoplay muted loop playsinline height="100%">
            <source src="static/images/focus-seven.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-eight">
          <video poster="" id="eight" autoplay muted loop playsinline height="100%">
            <source src="static/images/focus-eight.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-nine">
          <video poster="" id="nine" autoplay muted loop playsinline height="100%">
            <source src="static/images/focus-nine.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-ten">
          <video poster="" id="ten" autoplay muted loop playsinline height="100%">
            <source src="static/images/focus-ten.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We propose <em>SparseFusion</em>, a sparse view 3D reconstruction approach that unifies recent advances in neural rendering and probabilistic image generation.
          </p>
          <p>
            Existing approaches typically build on neural rendering with re-projected features but fail to generate unseen regions or handle uncertainty under large viewpoint changes. Alternate methods treat this as a (probabilistic) 2D synthesis task, and while they can generate plausible 2D images, they do not infer a consistent underlying 3D. However, we find that this trade-off between 3D consistency and probabilistic image generation does not need to exist. In fact, we show that geometric consistency and generative inference can be complementary in a mode seeking behavior.
          </p>
          <p>
            By distilling a 3D consistent scene representation from a view-conditioned latent diffusion model, we are able to recover a plausible 3D representation whose renderings are both accurate and realistic. We evaluate our approach across 51 categories in the CO3D dataset and show that it outperforms existing methods, in both distortion and perception metrics, for sparse view novel view synthesis.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/5077xFjWsIs"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      <!-- <div class="column">
        <div class="content">
          <h2 class="title is-3">Left</h2>
          <p>
            p
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="#"
                    type="video/mp4">
          </video>
        </div>
      </div> -->
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <!-- <div class="column">
        <h2 class="title is-3">Right</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              p
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src=""
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div> -->
    <!--/ Matting. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2>

        <!-- Subsection. -->
        <h3 class="title is-4">Comparison Against Existing Methods</h3>
        <div class="content has-text-justified">
          <p>
            We compare novel view synthesis on 10 categories from CO3D. Please see randomly selected results from all 51 categories <a href="comparison.html#all">here</a>. 
          </p>
        </div>
        <div class="content has-text-centered">
          <video class="rounded" id=""
                 controls
                 autoplay
                 loop
                 muted
                 playsinline
                 width="75%">
            <source src="static/images/comparison-a.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!--/ Subsection. -->

        <!-- Subsection. -->
        <h3 class="title is-4">Varying Number of Input Views</h3>
        <div class="content has-text-justified">
          <p>
            We compare novel view synthesis with varying number of input views. Please see randomly selected results from 10 categories <a href="comparison.html#views">here</a>. 
          </p>
        </div>
        <div class="content has-text-centered">
          <video class="rounded" id="replay-video"
                 controls
                 autoplay
                 loop
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="static/images/comp_v10_core.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!--/ Subsection. -->

        <!-- Subsection. -->
        <!-- <h3 class="title is-4">Additional Results</h3>
        <div class="content has-text-justified">
          <p>
            Please see randomly selected results from all 51 categories <a href="diverse.html">here</a>. 
          </p>
        </div>
        <div class="content has-text-centered">
          <video class="rounded" id="replay-video"
                 controls
                 autoplay
                 loop
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="static/images/focus-diverse.mp4"
                    type="video/mp4">
          </video>
        </div> -->
        <!--/ Subsection. -->

      </div>
    </div>
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
        </div>
      </div>
    </div>
    </div> -->

</section>




<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h3 class="title">Related Links</h2>
    <p>There are many exciting, related, and concurrent works, here are some of them. </p>
    <p><a href="https://dreamfusion3d.github.io/" target="_blank">DreamFusion</a>, <a href="https://deepimagination.cc/Magic3D/" target="_blank">Magic3D</a>, and <a href="https://pals.ttic.edu/p/score-jacobian-chaining" target="_blank">SJC</a> lifts 2D to 3D with large-scale diffusion models, enabling text-to-3d generation.</p>
    <p><a href="https://3d-diffusion.github.io/" target="_blank">3DiM</a> applies 2D diffusion models for multi-view consistent novel view synthesis.</p>
    <p><a href="https://jryanshue.com/nfd/" target="_blank">NFD</a> trains a triplane diffusion model to directly generate a 3D neural field.</p>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h3 class="title">BibTeX</h3>
    <pre>
<code>@inproceedings{zhou2023sparsefusion,
  title={SparseFusion: Distilling View-conditioned Diffusion for 3D Reconstruction}, 
  author={Zhizhuo Zhou and Shubham Tulsiani},
  booktitle={CVPR},
  year={2023}
}</code></pre>
  </div>
</section>

<section class="column" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h3 class="title">Acknowledgements</h2>
    <p>We thank Naveen Venkat, Mayank Agarwal, Jeff Tan, Paritosh Mittal, Yen-Chi Cheng, and Nikolaos Gkanatsios for helpful discussions and feedback.
    We also thank David Novotny and Jonáš Kulhánek for sharing outputs of their work and helpful correspondence.
    This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. (DGE1745016, DGE2140739).
    </p>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/abs/2212.00792">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/zhizdev/sparsefusion" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is made from this template <a href="https://github.com/nerfies/nerfies.github.io">source code</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
